import wikipedia
import os
import pickle



CACHE_DIR = "wiki_cache"
os.makedirs(CACHE_DIR, exist_ok=True)


# Список статей для загрузки
WIKI_ARTICLES = [
    "Динозавры", "Палеонтология", "Мезозой", "Мел-палеогеновое вымирание", "Оперённые динозавры",
    "Тероподы", "Архозавры", "Триасово-юрское вымирание","Мезозой",
    "Меловой период", "Фоссилии", "Археоптерикс", "Тираннозавр", "Трицератопс",
    "Велоцераптор", "Бронтозавр", "Птеродактили", "Морские рептилии", "Аммониты",
    "Птерозавры", "Копролиты", "Эволюция динозавров", "Кайнозой", "Динозавры России",
    "Спинозавр", "Игуанодон", "Скулозавр", "Аллозавр", "Сеймосавр", "Пахицефалозавр",
    "Анкилозавр", "Диплодок", "Цератопсиды", "Орнитоподы", "Стиракозавр", "Саркозух",
    "Морфология динозавров", "Палеоэкология", "Палеоантропология", "Кости динозавров",
    "Окаменелости растений", "Палеогеография", "Геохронология", "Палеоклимат",
    "Палеозоология", "Палеоботаника", "Протоцератопс", "Овираптор", "Мегалозавр",
    "Скорпиозавр", "Палеонтологические раскопки", "Ихтиозавр", "Плезиозавр",
    "Мозазавр", "Рахитозавр", "Эдмонтозавр", "Дейноних", "Пахицефалозавриды",
    "Палеозой", "Карнотавр", "Гиганотозавр", "Целофизис", "Брахиозавр", "Пахиринхозавр",
    "Сальтозавр", "Микрораптор", "Апатозавр", "Цератозавр", "Стиракозавриды",
    "Эдмонтозавриды", "Авеметатарзалии", "Титанозавры", "Комсогнат", "Палеоартропод",
    "Палеоинвертебраты", "Окаменелости морских организмов", "Палеоокеанография",
    "Палеоботаника триасового периода", "Мезозойская флора", "Мезозойская фауна",
    "Морские ящеры", "Плезиозавриды", "Титанозавры", "Мадагаскарские динозавры",
    "Юрский парк", "Меловые динозавры", "Палеонтологические методы", "Травоядные динозавры",
    "Хищные динозавры", "Формирование фоссилий", "Палеоконтиненты", "Кладистика",
    "Эволюционная биология"
]


def load_wiki_articles():
    texts = {}
    for title in WIKI_ARTICLES:
        cache_file = os.path.join(CACHE_DIR, f"{title}.pkl")
        if os.path.exists(cache_file):
            with open(cache_file, "rb") as f:
                texts[title] = pickle.load(f)
            continue

        try:
            text = wikipedia.page(title).content
        except wikipedia.exceptions.DisambiguationError as e:
            text = wikipedia.page(e.options[0]).content
        except wikipedia.exceptions.PageError:
            print(f"Статья '{title}' не найдена")
            continue

        texts[title] = text
        with open(cache_file, "wb") as f:
            pickle.dump(text, f)

    return texts


